\newpage
\section{Eigenvectors and Eigenvalues}

\emph{Eigenvector}

An eigenvector of a square matrix \(A\) is a non-zero vector \(\vec{v}\) that, when multiplied by \(A\), results in a vector that is a scalar multiple of itself. In other words, the direction of the vector \(\mathbf{v}\) remains unchanged (up to scaling) when the linear transformation represented by \(A\) is applied to it.

\emph{Eigenvalue}

The scalar multiple, denoted by \(\lambda\), is called the eigenvalue associated with the eigenvector \(\mathbf{v}\). It represents the factor by which the eigenvector is scaled when transformed by the matrix \(A\).

Mathematically, the relationship between a square matrix \(A\), an eigenvector \(\vec{v}\), and its corresponding eigenvalue \(\lambda\) is expressed by the following equation:
\[
A\vec{v} = \lambda\vec{v}
\]

\subsection{How to find the Eigenvectors and Eigenvalues}

To find the eigenvalues and eigenvectors of a square matrix \(A\), we solve the eigenvalue equation:

\vspace{\baselineskip}
\textbf{1. Form the characteristic equation:}

    Rewrite the equation \(A\vec{v} = \lambda\vec{v}\) as 
    \((A - \lambda I)\vec{v} = \vec{0}\), where \(\lambda I\) is the identity matrix times \(\lambda\) because 
    this matrix encodes the multiplication by some scalar. 
    
    To have a non-trivial solution \(0\) for \(\vec{v}\), the matrix \((A - \lambda I)\) must be 
    singular, which means its determinant must be zero because otherwise \(\vec{v}\) would be 0. Thus, 
    we have the characteristic equation:
    \[
    \det(A - \lambda I) = 0
    \]

\textbf{2. Solve for the eigenvalues:}

Solve the characteristic equation for \(\lambda\). The solutions \(\lambda_1, \lambda_2, \dots, \lambda_n\) 
are the eigenvalues of the matrix \(A\).
\vspace{\baselineskip}

\textbf{3. Find the eigenvectors:}

For each eigenvalue \(\lambda_i\), substitute it back into the equation \((A - \lambda_i I)\vec{v} = \vec{0}\) and solve for the vector \(\vec{v}\). The non-zero solutions for \(\mathbf{v}\) are the eigenvectors corresponding to the eigenvalue \(\lambda_i\).

\subsection{How to diagonalize a matrix}

Diagonalizing a matrix involves finding a diagonal matrix that is similar to the given matrix. 
A square matrix \(A\) is diagonalizable if there exists an invertible matrix \(X\) made of eigenvectors of 
\(A\) such that \(X^{-1}AX = D\), where \(D\) is a diagonal matrix made of eigenvalues.

The order of the eigenvalue and eigenvectors matters if you choose \(\lambda_1, \lambda_2, \dots, \lambda_n\) then the 
order of the eigenvectors \(v_1, v_2, \dots, v_n\) must also correspond.
\vspace{\baselineskip}

The process of diagonalization is as follows:
\vspace{\baselineskip}

\textbf{1. Find the eigenvalues and eigenvectors of \(A\).}
\vspace{\baselineskip}

\textbf{2. Form the matrix \(X\):}

Create a matrix \(X\) whose columns are the linearly independent eigenvectors of \(A\).
\vspace{\baselineskip}

\textbf{3. Form the diagonal matrix \(D\):} 

Create a diagonal matrix \(D\) whose diagonal entries are the eigenvalues of \(A\), corresponding to the order of the eigenvectors in \(P\). That is, if the \(i\)-th column of \(P\) is the eigenvector corresponding to the eigenvalue \(\lambda_i\), then the \(i\)-th diagonal entry of \(D\) is \(\lambda_i\).
\vspace{\baselineskip}

\textbf{4. Verify the diagonalization:}
    
Check that \(X^{-1}AX = D\).
\vspace{\baselineskip}

A matrix \(A\) is diagonalizable if and only if it has \(n\) linearly independent eigenvectors, where \(n\) is the size of the matrix.
\vspace{\baselineskip}

\textbf{Example: }
\vspace{\baselineskip}

Consider the matrix
\[
A = \begin{pmatrix}
2 & 1 \\
1 & 2
\end{pmatrix}
\]

\textbf{Step 1: Find the eigenvalues:}

The characteristic equation is
    \[
    \det(A - \lambda I) = \det \begin{pmatrix}
    2 - \lambda & 1 \\
    1 & 2 - \lambda
    \end{pmatrix} = (2 - \lambda)^2 - 1 = \lambda^2 - 4\lambda + 3 = 0
    \]
    Solving for \(\lambda\), we get \(\lambda_1 = 1\) and \(\lambda_2 = 3\).

\textbf{Step 2: Find the eigenvectors:}

For \(\lambda_1 = 1\):
    \[
    (A - I)\mathbf{v} = \begin{pmatrix}
    1 & 1 \\
    1 & 1
    \end{pmatrix} \begin{pmatrix}
    x \\
    y
    \end{pmatrix} = \begin{pmatrix}
    0 \\
    0
    \end{pmatrix}
    \]
    This gives \(x + y = 0\), so an eigenvector is \(\mathbf{v}_1 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}\).

    For \(\lambda_2 = 3\):
    \[
    (A - 3I)\vec{v} = \begin{pmatrix}
    -1 & 1 \\
    1 & -1
    \end{pmatrix} \begin{pmatrix}
    x \\
    y
    \end{pmatrix} = \begin{pmatrix}
    0 \\
    0
    \end{pmatrix}
    \]
    This gives \(-x + y = 0\), so an eigenvector is \(\mathbf{v}_2 = \begin{pmatrix} 1 \\ 1 \end{pmatrix}\).

\textbf{Step 3: Diagonalize the matrix:}

Let \(P = \begin{pmatrix} 1 & 1 \\ -1 & 1 \end{pmatrix}\). Then \(P^{-1} = \frac{1}{2} \begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix}\).
    \[
    P^{-1}AP = \frac{1}{2} \begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix} \begin{pmatrix} 1 & 1 \\ -1 & 1 \end{pmatrix} = \begin{pmatrix} 1 & 0 \\ 0 & 3 \end{pmatrix} = D
    \]
    Thus, \(A\) is diagonalized as \(P^{-1}AP = D\).
