\section{Linear Systems of Equations}

In this section, we will discuss the solution of linear systems of equations. A linear system of equations is a set of equations that can be expressed in the form:
\begin{align*}
a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n & = b_1  \\
a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n & = b_2  \\
& \vdots \\
a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n & = b_m
\end{align*}

where \( a_{ij} \) are the coefficients of the variables \( x_j \), and \( b_i \) are the constants on the right-hand side of the equations. The goal is to find the values of \( x_1, x_2, \ldots, x_n \) that satisfy all equations simultaneously.

\subsection{Matrix Representation}

A linear system can be represented in matrix form as:
\begin{equation*}
	A \mathbf{x} = \mathbf{b}
\end{equation*}
where \( A \) is the coefficient matrix, \( \mathbf{x} \) is the vector of variables, and \( \mathbf{b} \) is the vector of constants. The coefficient matrix \( A \) is an \( m \times n \) matrix, where \( m \) is the number of equations and \( n \) is the number of variables.
The vector \( \mathbf{x} \) is an \( n \times 1 \) column vector, and the vector \( \mathbf{b} \) is an \( m \times 1 \) column vector. The system can be solved using various methods, including:

\begin{itemize}[label=\(-\)]
	\item Gaussian elimination
	\item LU decomposition
	\item Matrix inversion (if \( A \) is square and invertible)
	\item Iterative methods (e.g., Jacobi, Gauss-Seidel)
	\item Special methods for sparse matrices
	\item Special methods for structured matrices (e.g., banded, Toeplitz)
	\item Special methods for large-scale problems (e.g., conjugate gradient, GMRES)
\end{itemize}

\subsection{Gaussian Elimination}

Gaussian elimination is a method for solving linear systems by transforming the system into an upper triangular form. The steps involved in Gaussian elimination are:
\begin{enumerate}
	\item Forward elimination: Transform the system into an upper triangular form by eliminating the variables from the equations.
	\item Back substitution: Solve for the variables starting from the last equation and substituting back into the previous equations.
\end{enumerate}
The forward elimination process involves performing row operations on the augmented matrix \([A | \mathbf{b}]\) to create zeros below the diagonal. The row operations include:
\begin{itemize}[label=\(-\)]
	\item Swapping two rows
	\item Multiplying a row by a non-zero scalar
	\item Adding or subtracting a multiple of one row from another row
\end{itemize}
Once the matrix is in upper triangular form, back substitution is used to find the values of the variables. The last equation gives the value of the last variable, which can then be substituted into the previous equations to find the other variables.

\subsection{Gauss-Jordan Elimination}

Gauss-Jordan elimination is an extension of Gaussian elimination that transforms the matrix into reduced row echelon form (RREF). In RREF, each leading entry in a row is 1, and all entries above and below the leading entry are zeros. The steps involved in Gauss-Jordan elimination are:
\begin{enumerate}
	\item Forward elimination: Transform the system into an upper triangular form.
	\item Back substitution: Transform the upper triangular matrix into RREF by eliminating the entries above the leading 1s.
	\item Solve for the variables directly from the RREF matrix.
\end{enumerate}
The Gauss-Jordan elimination method is particularly useful for finding the inverse of a matrix, as it can be applied to the augmented matrix \([A | I]\), where \(I\) is the identity matrix. If the left side of the augmented matrix becomes \(I\), then the right side will be the inverse of \(A\).

\textbf{Example:} Solve the following system of equations using Gaussian elimination:
\begin{align*}
	2x + 3y + z  & = 1 \\
	4x + y - z   & = 2 \\
	-2x + y + 3z & = 3
\end{align*}
\textbf{Solution:} The augmented matrix for the system is:
\begin{equation*}
	\begin{bmatrix}
		2  & 3 & 1  & | & 1 \\
		4  & 1 & -1 & | & 2 \\
		-2 & 1 & 3  & | & 3
	\end{bmatrix}
\end{equation*}
Performing row operations to eliminate the variables, we can transform the matrix into upper triangular form:
\begin{equation*}
	\begin{bmatrix}
		1 & \frac{3}{2} & \frac{1}{2} & | & \frac{1}{2} \\
		0 & -5          & -3          & | & 0           \\
		0 & 0           & 1           & | & 1
	\end{bmatrix}
\end{equation*}
Now, we can perform back substitution to find the values of \(x\), \(y\), and \(z\):
\begin{align*}
	z           & = 1                           \\
	-5y - 3z    & = 0 \implies y = -\frac{3}{5} \\
	2x + 3y + z & = 1 \implies x = \frac{1}{5}
\end{align*}
Thus, the solution to the system is:
\begin{align*}
	x & = \frac{1}{5}  \\
	y & = -\frac{3}{5} \\
	z & = 1
\end{align*}

\subsection{Homogeneous Linear Equations}

A linear equation is said to be \emph{homogeneous} if its constant term is zero. That is, it can be written in the form:
\[
	a_1x_1 + a_2x_2 + \cdots + a_nx_n = 0
\]

Such equations always have at least the trivial solution \(x_1 = x_2 = \cdots = x_n = 0\).

\subsection{Particular Solution}
A particular solution to a linear system of equations is a specific solution that satisfies the system. It can be found using various methods, including substitution, elimination, or matrix methods. A particular solution is not unique; there may be multiple particular solutions depending on the system.
A particular solution can be found by substituting specific values for the variables and solving for the remaining variables. For example, in the system
\begin{align*}
	2x + 3y & = 5 \\
	4x - y  & = 1
\end{align*}
we can substitute \(x = 1\) into the first equation to find \(y\):
\begin{align*}
	2(1) + 3y & = 5 \\
	3y        & = 3 \\
	y         & = 1
\end{align*}
Thus, \((x, y) = (1, 1)\) is a particular solution to the system. However, this is not the only solution; other values of \(x\) may yield different values of \(y\).

\subsection{General = Particular + Homogeneous}
The general solution of a linear system of equations is the complete set of solutions that satisfy the system. It can be expressed as the sum of a particular solution and the general solution of the associated homogeneous system.
The general solution can be written as:
\begin{equation*}
	\mathbf{x} = \mathbf{x}_p + \mathbf{x}_h
\end{equation*}
where \( \mathbf{x}_p \) is a particular solution to the non-homogeneous system, and \( \mathbf{x}_h \) is the general solution to the homogeneous system.
The homogeneous system is obtained by setting the right-hand side of the equations to zero:
\begin{equation*}
	A \mathbf{x} = \mathbf{0}
\end{equation*}

 The theoreme says:

Any linear system's solution set has the form:
\[
	\left\{ \vec{p} + c_1\vec{\beta}_1 + \cdots + c_k\vec{\beta}_k \;\middle|\; c_1, \ldots, c_k \in \mathbb{R} \right\}
\]

where \(\vec{p}\) is a particular solution to the system, and the vectors \(\vec{\beta}_1, \ldots, \vec{\beta}_k\) form a basis of the solution space to the corresponding homogeneous system. The number \(k\) equals the number of \textbf{free variables} the system has after applying Gaussian elimination.

\subsection{Linear Combination Lemma}
Any linear combination of linear combinations is a linear combination.

\subsection{Example: Gaussian Elimination with 3 Equations and 4 Unknowns}

Consider the following system of linear equations:

\begin{align*}
	x_1 + 2x_2 + x_3 + x_4   & = 4  \\
	2x_1 + 5x_2 + x_3 + 3x_4 & = 10 \\
	x_1 + 3x_2 + 2x_3 + 2x_4 & = 7
\end{align*}

\subsubsection*{Step 1: Augmented Matrix}

\[
	\begin{bmatrix}
		1 & 2 & 1 & 1 & 4  \\
		2 & 5 & 1 & 3 & 10 \\
		1 & 3 & 2 & 2 & 7  \\
	\end{bmatrix}
\]

\subsubsection*{Step 2: Eliminate below pivot in column 1}

\begin{itemize}[label=\(-\)]
	\item Row 2 = Row 2 - 2 Ã— Row 1
	\item Row 3 = Row 3 - Row 1
\end{itemize}

\[
	\begin{bmatrix}
		1 & 2 & 1  & 1 & 4 \\
		0 & 1 & -1 & 1 & 2 \\
		0 & 1 & 1  & 1 & 3 \\
	\end{bmatrix}
\]

\subsubsection*{Step 3: Eliminate below pivot in column 2}

\begin{itemize}[label=\(-\)]
	\item Row 3 = Row 3 - Row 2
\end{itemize}

\[
	\begin{bmatrix}
		1 & 2 & 1  & 1 & 4 \\
		0 & 1 & -1 & 1 & 2 \\
		0 & 0 & 2  & 0 & 1 \\
	\end{bmatrix}
\]

\subsubsection*{Step 4: Back Substitution}

From Row 3:
\[
	2x_3 = 1 \Rightarrow x_3 = \frac{1}{2}
\]

From Row 2:
\[
	x_2 - x_3 + x_4 = 2 \Rightarrow x_2 = 2 + x_3 - x_4 = 2 + \frac{1}{2} - x_4 = \frac{5}{2} - x_4
\]

From Row 1:
\[
	x_1 + 2x_2 + x_3 + x_4 = 4
	\Rightarrow x_1 = 4 - 2x_2 - x_3 - x_4
\]
Substitute:
\[
	x_1 = 4 - 2\left( \frac{5}{2} - x_4 \right) - \frac{1}{2} - x_4
	= 4 - 5 + 2x_4 - \frac{1}{2} - x_4
	= -1 - \frac{1}{2} + x_4 = -\frac{3}{2} + x_4
\]

\subsubsection*{General Solution}

Let \(x_4 = t\) (free variable), then:

\[
	\begin{aligned}
		x_1 & = -\frac{3}{2} + t \\
		x_2 & = \frac{5}{2} - t  \\
		x_3 & = \frac{1}{2}      \\
		x_4 & = t
	\end{aligned}
	\quad \text{with } t \in \mathbb{R}
\]

\textbf{Solution Set:}

\[
	\left\{
	\begin{pmatrix}
		-\frac{3}{2} \\ \frac{5}{2} \\ \frac{1}{2} \\ 0
	\end{pmatrix}
	+ t \cdot
	\begin{pmatrix}
		1 \\ -1 \\ 0 \\ 1
	\end{pmatrix}
	\;\middle|\; t \in \mathbb{R}
	\right\}
\]

\subsection{The Determinant, the cross product and the solutions of linear Systems of Equations}
A linear system of three equation has the following properties:

\begin{itemize}[label=\(-\)]
	\item There is a unique solution if the determinant of the coefficient matrix is non-zero. 
	\[\langle (a x b), c\rangle = \det(a,b,c) \ne 0\]
	\item There are infinitely many solutions if the determinant of the coefficient matrix is zero.
	\[\langle (a x b), c\rangle = \det(a,b,c) = 0\]
	\item There is no solution if the determinant of the coefficient matrix is zero and the system is inconsistent.
	\[\langle (a x b), c\rangle = 0\]
\end{itemize}

\newpage