\newpage
\section{Multi-variable Functions}

\subsection{Open Sets}

Let \( \| \cdot \| \) be a norm on \( \Reals^n \). The \( \varepsilon \)-neighborhood of a 
point \( \vec{x}_0 \in \Reals^n \) is defined as:

\[
    U_\varepsilon(\vec{x}_0) := \left\{ \vec{x} \in \Reals^n \mid \| \vec{x} - \vec{x}_0 \| 
    < \varepsilon \right\}
\]

A point \( \vec{x}_0 \in D \subseteq \Reals^n \) is called an \emph{interior point} of \( D \) 
if there exists \( \varepsilon > 0 \) such that \( U_\varepsilon(\vec{x}_0) \subseteq D \).  
A set \( D \) is called \emph{open} if all its points are interior points.

Although \( \varepsilon \)-neighborhoods depend on the chosen norm, due to the equivalence of norms 
in \( \Reals^n \), openness is norm-independent.

\subsection{Closed Sets}

Let \( D \subseteq \Reals^n \) and \( \| \cdot \| \) a norm. A point \( \vec{x}_0 \) is called 
an \emph{accumulation point} (or limit point) of \( D \) if for every \( \varepsilon > 0 \), the 
neighborhood \( U_\varepsilon(\vec{x}_0) \) contains a point \( \vec{x} \ne \vec{x}_0 \) such that 
\( \vec{x} \in D \).

A set \( D \subseteq \Reals^n \) is called \emph{closed} if it contains all its accumulation points.

\subsection{Boundedness and Order}

A set \( D \subseteq \Reals^n \) is called \emph{bounded} if there exists a real number \( M > 0 \) 
such that:

\[
    \|\vec{x}\| < M \quad \text{for all } \vec{x} \in D
\]

If no such bound \( M \) exists, the set is called \emph{unbounded}.

\subsection{Sequences}

Let \( (\vec{x}_n) \subseteq \Reals^n \) be a sequence of vectors. We say that 
\( \vec{x}_n \to \vec{x} \in \Reals^n \) as \( n \to \infty \) if for every \( \varepsilon > 0 \), 
there exists \( n_0 \in \Naturals \) such that:
    
\[
    \|\vec{x}_n - \vec{x}\| < \varepsilon \quad \text{for all } n > n_0
\]

The sequence \( (\vec{x}_n) \) is called \emph{convergent} if such \( \vec{x} \) exists.

The sequence \( (\vec{x}_n) \) is called a \emph{Cauchy sequence} if for every \( \varepsilon > 0 \), 
there exists \( n_0 \in \Naturals \) such that:

\[
    \|\vec{x}_n - \vec{x}_m\| < \varepsilon \quad \text{for all } n, m > n_0
\]

\textbf{Example I:}

\[
    \lim_{n \to \infty} \vec{X}_n = \lim_{n \to \infty} \begin{bmatrix} \frac{1}{n} \\
    1 + \frac{1}{n^2} \\ \frac{\sin n}{n}\end{bmatrix} = \begin{bmatrix}
        0 \\ 1 \\ 0
    \end{bmatrix}
\]

\subsection{Different Norms}

From linear algebra it is known what a \emph{Norm} is and its properties:

Let \( V \) be a vector space over \( \Reals \) or \( \Complex \). A function 
\( \|\cdot\|: V \to \Reals \) is called a norm if for all \( x, y \in V \) and all scalars 
\( \alpha \), the following properties hold:

\begin{enumerate}
    
    \item \emph{Non-negativity:} \( \|x\| \geq 0 \), and \( \|x\| = 0 \) if and only if \( x = 0 \).
    
    \item \emph{Absolute homogeneity:} \( \|\alpha x\| = |\alpha| \cdot \|x\| \).
    
    \item \emph{Triangle inequality:} \( \|x + y\| \leq \|x\| + \|y\| \).

\end{enumerate}

Commonly used norms in \( \Reals^n \) (or \( \Complex^n \)) include:

\begin{itemize}
    
    \item \emph{Sum Norm} (also known as the \( \ell_1 \) norm): 
    
    \[
        \|x\|_1 = \sum_{i=1}^n |x_i|
    \]
    
    \item \emph{Max Norm} (also known as the \( \ell_\infty \) norm): 
    
    \[
        \|x\|_\infty = \max_{1 \leq i \leq n} |x_i|
    \]
    
    \item \emph{Euclidean Norm} (also known as the \( \ell_2 \) norm): 
    
    \[
        \|x\|_2 = \left( \sum_{i=1}^n |x_i|^2 \right)^{1/2}
    \]

\end{itemize}

\textbf{Example II:}

Given is

\[
    \vec{X}_n = 
    \begin{bmatrix}
    5 - \frac{10}{n}\\
    \frac{1}{n}   
    \end{bmatrix}
\]

we want to find \(n_0\) for \(\varepsilon = 0,1\)

\[
    \lim_{n \to \infty} \vec{X}_n = 
    \begin{bmatrix}
    5 \\
    0
    \end{bmatrix}
    = \vec{X}_0
\]

Now use the definition for convergence and \emph{Euclidean Norm}

\[
    \|\vec{X}_n - \vec{X}_0\| < \varepsilon
\]

\[
    \left\| 
    \begin{bmatrix}
        -\frac{10}{n}\\
        \frac{1}{n}
    \end{bmatrix}
    \right\|
\]

\[
    \frac{\sqrt{101}}{n} < 0,1
\]
\[
    n > 0,1 \sqrt{101} = 100,5
\]

Therefore, \(n_0 = 101\).

\subsubsection{Equivalence of Norms}

In finite-dimensional vector spaces, all norms are equivalent. That is, if \( \|\cdot\|_a \) and 
\( \|\cdot\|_b \) are two norms on a finite-dimensional vector space \( V \), then there exist constants 
\( c, C > 0 \) such that for all \( x \in V \),

\[
    c \|x\|_a \leq \|x\|_b \leq C \|x\|_a
\]

This implies that while different norms may measure length differently, they all 
induce the same topology and convergence behavior in finite-dimensional spaces.

\subsubsection{Equivalence in the Reals}

In the \(\Reals^n\) all norms are equivalent and 

\begin{align*}
     \|\vec{x}\|_\infty &\le \|\vec{x}\|_2 \le \sqrt{n}\|\vec{x}\|_\infty \\
     \|\vec{x}\|_\infty &\le \|\vec{x}\|_1 \le n\|\vec{x}\|_\infty \\
     \|\vec{x}\|_2 &\le \|\vec{x}\|_1 \le n\|\vec{x}\|_2
\end{align*}

\subsection{Accumulation Point}

A vector \( \vec{x}_0 \in \Reals^n \) is called an \emph{accumulation point} of a set 
\( D \subseteq \Reals^n \) if for every \( \varepsilon > 0 \), the neighborhood 
\( U_\varepsilon(\vec{x}_0) \) contains a point \( \vec{x} \in D \setminus \{\vec{x}_0\} \).

In the context of sequences, an accumulation point of a sequence \( (\vec{x}_n) \) is a point 
\( \vec{x} \in \Reals^n \) for which there exists a subsequence \( (\vec{x}_{n_k}) \) such that 
\( \vec{x}_{n_k} \to \vec{x} \).

\subsection{Bolzano–Weierstraß Theorem}

Every infinite, bounded sequence in \( \Reals^n \) has at least one accumulation point.

\begin{itemize}
    
    \item Every bounded infinite sequence has at least one convergent subsequence.

    \item A bounded sequence is \emph{convergent} if and only if it has exactly one accumulation point.

    \item Every Cauchy sequence in \( \Reals^n \) is convergent (since \( \Reals^n \) is complete).

\end{itemize}

\subsection{Limits}

A function \( f : U \subseteq \Reals^n \to \Reals \) has the limit \( g \in \Reals \) at a 
point \( \vec{X}_0 \in U \) if:

\[
    \lim_{\vec{X} \to \vec{X}_0} f(\vec{X}) = g
\]

means that for every sequence \( (\vec{X}_n) \subset U \) converging to \( \vec{X}_0 \), we have:

\[
    \lim_{n \to \infty} f(\vec{X}_n) = g
\]

The convergence must hold along all possible paths to the point \( \vec{X}_0 \), making the 
multi-variable limit path-independent and unique (if it exists).

\textbf{Example:}

\(\vec{X}_n = \begin{bmatrix} \frac{1}{n} \\ 1 + \frac{1}{n^2} \\ \frac{\sin(n)}{n} \end{bmatrix}\)

The limit towards infinity is then 

\[
    \lim_{n \to \infty} \begin{bmatrix} \frac{1}{n} \\ 1 + \frac{1}{n^2} \\ \frac{\sin(n)}{n} \end{bmatrix}
    = \begin{bmatrix}
        0 \\ 1 \\ 0
    \end{bmatrix}
\]

\subsection{Partial Functions}

For a function \( f: U \subseteq \Reals^n \to \Reals \), a \emph{partial function} is a 
restriction of \(f\) to a variable by fixing all others.

\textbf{Examples in \( \Reals^3 \):}

\[
    f(x_1, x_2, x_3) = 5x_1 + x_2 x_3
\]

Fixing values:

\[
    x_2 = 3, \quad x_3 = 5 \Rightarrow f_1(x_1) = 5x_1 + 15 
\]
\[
    x_1 = 2, \quad x_3 = 5 \Rightarrow f_2(x_2) = 10 + 5x_2 \\
    x_1 = 2, \quad x_2 = 3 \Rightarrow f_3(x_3) = 10 + 3x_3
\]

Each \( f_i \) reduces the multi-variable function to a single-variable slice (cross-section), 
allowing analysis along coordinate axes.

\subsection{Continuity}

Let \( f : U \subseteq \Reals^n \to \Reals \), and \( \vec{X}_0 \in U \). The function 
\(f\) is said to be \emph{continuous at \( \vec{X}_0 \)} if:

\[
    \lim_{\vec{X} \to \vec{X}_0} f(\vec{X}) = f(\vec{X}_0)
\]

This means that for any sequence \( (\vec{X}_n) \to \vec{X}_0 \), we have:

\[
    \lim_{n \to \infty} f(\vec{X}_n) = f(\vec{X}_0)
\]

To check if a multi-variable function is continuous it is enough to prove that it is continuous towards 
the origin

\begin{align*}
    \lim_{\vec{X} \to \vec{X_0}}f(\vec{X}) &= f(\vec{X_0}) \\
    &\iff \lim_{\vec{X} \to \vec{X_0}} \left(f(\vec{X}) - f(\vec{X_0})\right) = 0 \\
    &\iff \lim_{\vec{h} \to 0} \left(f(\vec{X_0} + \vec{h}) - f(\vec{X_0})\right) = 0 \\
    &\iff \lim_{\vec{h} \to 0} g(\vec{h}) = 0
\end{align*}

If we are checking if a function is continuous and get an \emph{indeterminate form} there are three main 
approaches.

\begin{enumerate}
    
    \item \emph{Factorizing}: Either normal factorization, adding a clever zero or multiplying by a clever 
          one.
    
    \item \emph{Change of Coordinates}: Sometimes changing the coordinate system allows us to simplify the 
          expression.
    
    \item \emph{Different Paths}: Trying different paths can be pretty straightforward. If wet two 
          different values for the same point across different paths then the function is not continuous.

\end{enumerate}

\textbf{Example:}

Given is \(\frac{x^3 + 2yx^2 + y^2x + 2y^3}{x + 2y}\) for \((x,y) \ne (0,0)\) and \(0 for (0,0)\).

\begin{align*}
    \frac{x^3 + 2yx^2 + y^2x + 2y^3}{x + 2y} &= (\frac{x^2(x + 2y) + y(x + 2y)}{x + 2y}\\
    &= \frac{(x + 2y)(x^2 + y^2)}{x + 2y}\\
    &= x^2 + y^2
\end{align*}

Now by taking the limit we see that

\[
    \lim_{(x,y) \to (0,0)} x^2 + y^2 = 0
\]

Thus, the function is continuous.

\textbf{Example:}

Check for continuity towards the origin of \(f(x,y) =\frac{xy^2}{x^2 + y^4}\).

For the path \(x = y\) and \(y = 0\)

\[
    f(x,0) = \frac{x0}{x^2 + 0} = 0
\]

For the path \(x = y^2\)

\[
    f(y^2, y) = \frac{y^4}{2y^4} = \frac{1}{2}
\]

Because we got two different values the function is not continuous.

\subsubsection{Continuity in Polar Coordinates for 2D}

Let \( \vec{X} = (x, y) \) be written in polar coordinates:

\[
    x = r \cos \varphi, \quad y = r \sin \varphi
\]

Then:

\[
    \vec{X}_n \to (0, 0) \iff r_n \to 0
\]

This alternative approach helps evaluate limits and continuity at the origin using radial convergence.

\textbf{Example:}

Given is 

\[
    f(xy) = 
    \begin{cases}   
    \frac{xy}{x^2 + y^2} \text{ for } (x,y) \ne (0,0) \\ 
    0 \text{ else }
    \end{cases}
\]

Let \(x = r\cos(\theta)\) and \(y = r\sin(\theta)\)

\begin{align*}
    \lim_{r \to 0} \frac{r\cos(\theta)r\sin(\theta)}{r^2\cos^2(\theta) + r^2\sin^2(\theta)}\\
    = \lim_{r \to 0} \frac{r^2\cos(\theta)\sin(\theta)}{r^2(\cos^2(\theta) + \sin^2(\theta))}\\
    = \lim_{r \to 0} \frac{\cos(\theta)\sin(\theta)}{1}
\end{align*}

Because of the dependence on \(\theta\) which can give us for \(\theta = \frac{\pi}{4}\) \(\frac{1}{2}\) 
this functions is not continuous.

\subsubsection{Substitution}

When dealing with multi-variable functions we can sometimes use \emph{substitution} 
for converting our function into a single variable function to use \emph{L'Hospital's Rule}.

\textbf{Example:}

Given is \(\frac{e^{x^2 + y^2} - 1}{x^2 + y^2}\).

See, that we have repeated terms we can substitute. \(p^2 = x^2 + y^2\).

\[
    \frac{e^{p^2} - 1}{p^2}
\]

Now differentiate

\[
    \frac{2p e^{p^2} }{2p} = e^{p^2}
\]

Now take the limit

\[
    \lim_{p \to 0} e^{p^2} = 1
\]

\subsection{Uniform and Lipschitz Continuity}

\subsubsection{Uniform Continuity:}  
A function \( f : D \subseteq \Reals^n \to \Reals \) is called \emph{uniformly continuous} on 
\( D \) if:

\[
    \forall \varepsilon > 0 \ \exists \delta > 0 \text{ such that } \|\vec{X} - \vec{X}_0\| < \delta 
    \Rightarrow |f(\vec{X}) - f(\vec{X}_0)| < \varepsilon
\]

The key feature is that \( \delta \) depends only on \( \varepsilon \), not on the points 
\( \vec{X}, \vec{X}_0 \) themselves.  
If \(f\) is continuous on a compact set (closed and bounded), then \(f\) is uniformly continuous.

\subsubsection{Lipschitz Continuity:}  

A function \( f : D \subseteq \Reals^n \to \Reals \) is \emph{Lipschitz continuous} if there 
exists a constant \( L > 0 \) such that:

\[
    |f(\vec{X}) - f(\vec{Y})| \le L \|\vec{X} - \vec{Y}\| \quad \text{for all } \vec{X}, \vec{Y} \in D
\]

If \( L < 1 \), then \(f\) is called a \emph{contraction}.

\subsection{Epsilon–Delta Criterion}

Let \( f : D \subseteq \Reals^n \to \Reals \), and \( \vec{X}_0 \in D \). The function 
\(f\) is continuous at \( \vec{X}_0 \) if:

\[
    \forall \varepsilon > 0 \ \exists \delta > 0 \text{ such that } \|\vec{X} - \vec{X}_0\| 
    < \delta \Rightarrow |f(\vec{X}) - f(\vec{X}_0)| < \varepsilon
\]

This generalizes the familiar epsilon-delta criterion from single-variable calculus to multi-variable 
settings using norms.

\subsection{Fixpoints}
  
A point \( \vec{X}_0 \in D \subseteq \Reals^n \) is called a \emph{fix-point} of a function 
\( \vec{\varphi} : D \to \Reals^n \) if:

\[
    \vec{\varphi}(\vec{X}_0) = \vec{X}_0
\]

That is, applying the function does not change the point — it maps to itself.

\subsection{Banach Fixed Point Theorem}

Let \( \vec{\varphi} : D \subseteq \Reals^n \to \Reals^n \) be a \emph{contraction mapping}, 
i.e., there exists a constant \( L < 1 \) such that:

\[
    \|\vec{\varphi}(\vec{X}) - \vec{\varphi}(\vec{Y})\| \le L \|\vec{X} - \vec{Y}\| \quad 
    \text{for all } \vec{X}, \vec{Y} \in D
\]

Then:

\begin{itemize}
    \item There exists a unique fix-point \( \vec{X}^* \in D \) such that 
    \( \vec{\varphi}(\vec{X}^*) = \vec{X}^* \)
    \item Iteratively defined sequences \( \vec{X}_{n+1} = \vec{\varphi}(\vec{X}_n) \) converge to the 
    fix-point
\end{itemize}

This result is fundamental in nonlinear analysis and iterative numerical methods.

\subsection{Vector fields}

A \emph{vector field} is a function \(\vec{f}: \Reals^n \to \Reals^n\). Also, just a 
function with vectors as inputs and outputs.

\[
    \vec{f}(x_1, x_2, \dots, x_n) = A_1(x_1, \dots, x_n)\vec{e}_1 + \cdots + A_n(x_1, \dots, x_n)\vec{e}_n
\]

We call a vector field \emph{continuous}/\emph{differentiable} if all functions 

\[
    A_1, A_2, \dots, A_n
\] 

are continuous/differentiable.

As a side node, the \emph{gradient} of a multi-variable function is a vector field.

