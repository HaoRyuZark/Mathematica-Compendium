\newpage
\section{Multi-variable Functions}

\subsection{Open Sets}

Let \( \| \cdot \| \) be a norm on \( \mathbb{R}^n \). The \( \varepsilon \)-neighborhood of a point \( \vec{x}_0 \in \mathbb{R}^n \) is defined as:
\[
U_\varepsilon(\vec{x}_0) := \left\{ \vec{x} \in \mathbb{R}^n \mid \| \vec{x} - \vec{x}_0 \| < \varepsilon \right\}
\]

A point \( \vec{x}_0 \in D \subseteq \mathbb{R}^n \) is called an \emph{interior point} of \( D \) if there exists \( \varepsilon > 0 \) such that \( U_\varepsilon(\vec{x}_0) \subseteq D \).  
A set \( D \) is called \emph{open} if all its points are interior points.

\textbf{Note:} Although \( \varepsilon \)-neighborhoods depend on the chosen norm, due to the equivalence of norms in \( \mathbb{R}^n \), openness is norm-independent.


\subsection{Closed Sets}

Let \( D \subseteq \mathbb{R}^n \) and \( \| \cdot \| \) a norm. A point \( \vec{x}_0 \) is called an \emph{accumulation point} (or limit point) of \( D \) if for every \( \varepsilon > 0 \), the neighborhood \( U_\varepsilon(\vec{x}_0) \) contains a point \( \vec{x} \ne \vec{x}_0 \) such that \( \vec{x} \in D \).

A set \( D \subseteq \mathbb{R}^n \) is called \emph{closed} if it contains all its accumulation points.

\subsection{Boundedness and Order}

A set \( D \subseteq \mathbb{R}^n \) is called \emph{bounded} if there exists a real number \( M > 0 \) such that:
\[
\|\vec{x}\| < M \quad \text{for all } \vec{x} \in D
\]
If no such bound \( M \) exists, the set is called \emph{unbounded}.


\subsection{Sequences in \( \mathbb{R}^n \)}

Let \( (\vec{x}_n) \subseteq \mathbb{R}^n \) be a sequence of vectors. We say that \( \vec{x}_n \to \vec{x} \in \mathbb{R}^n \) as \( n \to \infty \) if for every \( \varepsilon > 0 \), there exists \( n_0 \in \mathbb{N} \) such that:
\[
\|\vec{x}_n - \vec{x}\| < \varepsilon \quad \text{for all } n > n_0
\]

The sequence \( (\vec{x}_n) \) is called \emph{convergent} if such \( \vec{x} \) exists.

The sequence \( (\vec{x}_n) \) is called a \emph{Cauchy sequence} if for every \( \varepsilon > 0 \), there exists \( n_0 \in \mathbb{N} \) such that:
\[
\|\vec{x}_n - \vec{x}_m\| < \varepsilon \quad \text{for all } n, m > n_0
\]

\textbf{Example: }

\[
\lim_{n \to \infty} \vec{X}_n = \lim_{n \to \infty} \begin{pmatrix} \frac{1}{n} \\
1 + \frac{1}{n^2} \\ \frac{\sin n}{n}\end{pmatrix} = \begin{pmatrix}
    0 \\ 1 \\ 0
\end{pmatrix}
\]

\subsection{Accumulation Point}

A vector \( \vec{x}_0 \in \mathbb{R}^n \) is called an \emph{accumulation point} of a set \( D \subseteq \mathbb{R}^n \) if for every \( \varepsilon > 0 \), the neighborhood \( U_\varepsilon(\vec{x}_0) \) contains a point \( \vec{x} \in D \setminus \{\vec{x}_0\} \).

In the context of sequences, an accumulation point of a sequence \( (\vec{x}_n) \) is a point \( \vec{x} \in \mathbb{R}^n \) for which there exists a subsequence \( (\vec{x}_{n_k}) \) such that \( \vec{x}_{n_k} \to \vec{x} \).

\subsection{Bolzano–Weierstraß Theorem}

Every infinite, bounded sequence in \( \mathbb{R}^n \) has at least one accumulation point.

\begin{itemize}[label=\(-\)]
\item Every bounded infinite sequence has at least one convergent subsequence.
\item A bounded sequence is \emph{convergent} if and only if it has exactly one accumulation point.
\item Every Cauchy sequence in \( \mathbb{R}^n \) is convergent (since \( \mathbb{R}^n \) is complete).
\end{itemize}

\subsection{Limits in \( \mathbb{R}^n \)}

A function \( f : U \subseteq \mathbb{R}^n \to \mathbb{R} \) has the limit \( g \in \mathbb{R} \) at a point \( \vec{X}_0 \in U \) if:

\[
\lim_{\vec{X} \to \vec{X}_0} f(\vec{X}) = g
\]

means that for every sequence \( (\vec{X}_n) \subset U \) converging to \( \vec{X}_0 \), we have:

\[
\lim_{n \to \infty} f(\vec{X}_n) = g
\]

The convergence must hold along all possible paths to the point \( \vec{X}_0 \), making the multi-variable limit path-independent and unique (if it exists).


\subsection{Partial Functions}

For a function \( f: U \subseteq \mathbb{R}^n \to \mathbb{R} \), a \emph{partial function} is a restriction of \( f \) to a variable by fixing all others.

\textbf{Examples in \( \mathbb{R}^3 \):}
\[
f(x_1, x_2, x_3) = 5x_1 + x_2 x_3
\]

Fixing values:
\[
x_2 = 3, \quad x_3 = 5 \Rightarrow f_1(x_1) = 5x_1 + 15 
\]
\[
x_1 = 2, \quad x_3 = 5 \Rightarrow f_2(x_2) = 10 + 5x_2 \\
x_1 = 2, \quad x_2 = 3 \Rightarrow f_3(x_3) = 10 + 3x_3
\]

Each \( f_i \) reduces the multi-variable function to a single-variable slice (cross-section), allowing analysis along coordinate axes.


\subsection{Continuity in \( \mathbb{R}^n \)}

Let \( f : U \subseteq \mathbb{R}^n \to \mathbb{R} \), and \( \vec{X}_0 \in U \). The function \( f \) is said to be \emph{continuous at \( \vec{X}_0 \)} if:

\[
\lim_{\vec{X} \to \vec{X}_0} f(\vec{X}) = f(\vec{X}_0)
\]

This means that for any sequence \( (\vec{X}_n) \to \vec{X}_0 \), we have:
\[
\lim_{n \to \infty} f(\vec{X}_n) = f(\vec{X}_0)
\]

To check if a multi-variable function is continuous it is enough to prove that it is continuous towards the origin

\begin{align*}
    \lim_{\vec{X} \to \vec{X_0}}f(\vec{X}) &= f(\vec{X_0}) \\
    &\iff \lim_{\vec{X} \to \vec{X_0}} \left(f(\vec{X}) - f(\vec{X_0})\right) = 0 \\
    &\iff \lim_{\vec{h} \to 0} \left(f(\vec{X_0} + \vec{h}) - f(\vec{X_0})\right) = 0 \\
    &\iff \lim_{\vec{h} \to 0} g(\vec{h}) = 0
\end{align*}

\subsubsection{Continuity in Polar Coordinates (in \( \mathbb{R}^2 \)):}

Let \( \vec{X} = (x, y) \) be written in polar coordinates:
\[
x = r \cos \varphi, \quad y = r \sin \varphi
\]

Then:
\[
\vec{X}_n \to (0, 0) \iff r_n \to 0
\]

This alternative approach helps evaluate limits and continuity at the origin using radial convergence.

\subsection{Uniform and Lipschitz Continuity}

\subsubsection{Uniform Continuity:}  
A function \( f : D \subseteq \mathbb{R}^n \to \mathbb{R} \) is called \emph{uniformly continuous} on \( D \) if:

\[
\forall \varepsilon > 0 \ \exists \delta > 0 \text{ such that } \|\vec{X} - \vec{X}_0\| < \delta \Rightarrow |f(\vec{X}) - f(\vec{X}_0)| < \varepsilon
\]

\textit{Note:} The key feature is that \( \delta \) depends only on \( \varepsilon \), not on the points \( \vec{X}, \vec{X}_0 \) themselves.  
If \( f \) is continuous on a compact set (closed and bounded), then \( f \) is uniformly continuous.

\subsubsection{Lipschitz Continuity:}  
A function \( f : D \subseteq \mathbb{R}^n \to \mathbb{R} \) is \emph{Lipschitz continuous} if there exists a constant \( L > 0 \) such that:

\[
|f(\vec{X}) - f(\vec{Y})| \le L \|\vec{X} - \vec{Y}\| \quad \text{for all } \vec{X}, \vec{Y} \in D
\]

If \( L < 1 \), then \( f \) is called a \emph{contraction}.



\subsection{Epsilon–Delta Criterion in \( \mathbb{R}^n \)}

Let \( f : D \subseteq \mathbb{R}^n \to \mathbb{R} \), and \( \vec{X}_0 \in D \). The function \( f \) is continuous at \( \vec{X}_0 \) if:

\[
\forall \varepsilon > 0 \ \exists \delta > 0 \text{ such that } \|\vec{X} - \vec{X}_0\| < \delta \Rightarrow |f(\vec{X}) - f(\vec{X}_0)| < \varepsilon
\]

This generalizes the familiar epsilon-delta criterion from single-variable calculus to multi-variable settings using norms.



\subsection{Fixpoints in \( \mathbb{R}^n \)}
  
A point \( \vec{X}_0 \in D \subseteq \mathbb{R}^n \) is called a \emph{fix-point} of a function \( \vec{\varphi} : D \to \mathbb{R}^n \) if:

\[
\vec{\varphi}(\vec{X}_0) = \vec{X}_0
\]

That is, applying the function does not change the point — it maps to itself.



\subsection{Banach Fixed Point Theorem in \( \mathbb{R}^n \)}

Let \( \vec{\varphi} : D \subseteq \mathbb{R}^n \to \mathbb{R}^n \) be a \emph{contraction mapping}, i.e., there exists a constant \( L < 1 \) such that:

\[
\|\vec{\varphi}(\vec{X}) - \vec{\varphi}(\vec{Y})\| \le L \|\vec{X} - \vec{Y}\| \quad \text{for all } \vec{X}, \vec{Y} \in D
\]

Then:
\begin{itemize}[label=\(-\)]
\item There exists a unique fix-point \( \vec{X}^* \in D \) such that \( \vec{\varphi}(\vec{X}^*) = \vec{X}^* \)
\item Iteratively defined sequences \( \vec{X}_{n+1} = \vec{\varphi}(\vec{X}_n) \) converge to the fix-point
\end{itemize}

This result is fundamental in nonlinear analysis and iterative numerical methods.


